{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\online.CSCENTER/nltk_data', 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data', 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data', 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\online.CSCENTER\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:\\\\Users\\\\online.CSCENTER\\\\AppData\\\\Roaming\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\online.CSCENTER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.data.path.append('C:\\\\Users\\\\online.CSCENTER\\\\AppData\\\\Roaming\\\\nltk_data')\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 15978\n",
      "Token count: 431079\n",
      "Type count: 12475\n",
      "\n",
      "Top 50 word types and their counts:\n",
      ",: 28941\n",
      ".: 13497\n",
      "to: 11926\n",
      "the: 11823\n",
      "and: 10725\n",
      "of: 10398\n",
      "a: 6554\n",
      "I: 6303\n",
      "her: 5952\n",
      "was: 5559\n",
      "in: 5316\n",
      ";: 5244\n",
      "'': 5171\n",
      "it: 4521\n",
      "not: 4511\n",
      "--: 4419\n",
      "be: 4218\n",
      "she: 3926\n",
      "that: 3878\n",
      "had: 3751\n",
      "``: 3664\n",
      "as: 3353\n",
      "for: 3246\n",
      "you: 3246\n",
      "he: 2995\n",
      "with: 2799\n",
      "have: 2690\n",
      "his: 2650\n",
      "is: 2346\n",
      "at: 2320\n",
      "but: 2298\n",
      "very: 2068\n",
      "all: 1988\n",
      "'s: 1974\n",
      "!: 1941\n",
      "so: 1872\n",
      "him: 1847\n",
      "could: 1836\n",
      "on: 1735\n",
      "by: 1699\n",
      "been: 1690\n",
      "would: 1671\n",
      "which: 1559\n",
      "were: 1453\n",
      "no: 1413\n",
      "my: 1363\n",
      "from: 1352\n",
      "?: 1290\n",
      "Mr.: 1259\n",
      "any: 1238\n",
      "\n",
      "Average sentence length: 26.98 words\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from collections import Counter\n",
    "\n",
    "# Download the Gutenberg corpus if not already downloaded\n",
    "\n",
    "\n",
    "# Load Jane Austen's novels\n",
    "\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "sense = gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "# Combine all three texts\n",
    "all_text = emma + persuasion + sense\n",
    "\n",
    "# A. Open and read the string content\n",
    "# B. Build a list of individual sentences\n",
    "sentences = nltk.sent_tokenize(all_text)\n",
    "\n",
    "# C. Print the number of sentences\n",
    "num_sentences = len(sentences)\n",
    "print(f\"Number of sentences: {num_sentences}\")\n",
    "\n",
    "# D. Build a flat tokenized word list and the type list\n",
    "words = nltk.word_tokenize(all_text)\n",
    "types = set(words)\n",
    "\n",
    "# E. Print token and type counts\n",
    "print(f\"Token count: {len(words)}\")\n",
    "print(f\"Type count: {len(types)}\")\n",
    "\n",
    "# F. Build a frequency count dictionary of words\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# G. Print the top 50 word types and their counts\n",
    "top_words = word_freq.most_common(50)\n",
    "print(\"\\nTop 50 word types and their counts:\")\n",
    "for word, freq in top_words:\n",
    "    print(f\"{word}: {freq}\")\n",
    "avg_sentence_length = sum(len(nltk.word_tokenize(sentence)) for sentence in sentences) / len(sentences)\n",
    "print(f\"\\nAverage sentence length: {avg_sentence_length:.2f} words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
