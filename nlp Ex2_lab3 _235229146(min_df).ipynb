{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NATURAL LANGUAGE PROCESSING.\n",
    " Exercise: 2\n",
    " NAME: vidhya S\n",
    " ROLL NUMBER:235229146\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default settings:\n",
      "Feature names: ['ate', 'away', 'cat', 'end', 'finally', 'from', 'had', 'house', 'little', 'mouse', 'of', 'ran', 'saw', 'story', 'the', 'tiny']\n",
      "Transformed matrix:\n",
      " [[0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 1 0 2 0]\n",
      " [0 1 0 0 0 1 0 1 0 1 0 1 0 0 2 0]\n",
      " [1 0 1 0 1 0 0 0 0 1 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 1 0 0 1 2 0]]\n",
      "\n",
      "Updated settings:\n",
      "Feature names: ['cat', 'house', 'mouse', 'the', 'the cat', 'the house', 'the mouse']\n",
      "Transformed matrix:\n",
      " [[0 1 1 1 0 1 0]\n",
      " [1 0 1 2 1 0 1]\n",
      " [0 1 1 2 0 1 1]\n",
      " [1 0 1 2 1 0 1]\n",
      " [0 0 1 2 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Define your corpus or text data\n",
    "corpus = [\n",
    "    \"the house had a tiny little mouse\",\n",
    "    \"the cat saw the mouse\",\n",
    "    \"the mouse ran away from the house\",\n",
    "    \"the cat finally ate the mouse\",\n",
    "    \"the end of the mouse story\"\n",
    "]\n",
    "\n",
    "# Initialize the CountVectorizer with default values\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus using the default settings\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print the feature names and the transformed matrix\n",
    "print(\"Default settings:\")\n",
    "print(\"Feature names:\", vectorizer.get_feature_names())\n",
    "print(\"Transformed matrix:\\n\", X.toarray())\n",
    "\n",
    "# Change the values of min_df and ngram_range\n",
    "min_df = 2  # Minimum document frequency\n",
    "ngram_range = (1, 2)  # Range of n-grams to consider\n",
    "\n",
    "# Initialize the CountVectorizer with the updated values\n",
    "vectorizer = CountVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "\n",
    "# Fit and transform the corpus using the updated settings\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print the feature names and the transformed matrix\n",
    "print(\"\\nUpdated settings:\")\n",
    "print(\"Feature names:\", vectorizer.get_feature_names())\n",
    "print(\"Transformed matrix:\\n\", X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
